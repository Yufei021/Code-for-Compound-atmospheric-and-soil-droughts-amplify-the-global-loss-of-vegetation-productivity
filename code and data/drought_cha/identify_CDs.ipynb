{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc82f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import os\n",
    "\n",
    "# load file\n",
    "vpd_path = r'G:\\paper01\\era5\\VPD_mon_Clip'\n",
    "sm_path = r'G:\\paper01\\era5\\sm_layer2_mon_res\\1'\n",
    "\n",
    "workspace_path = 'G:' \n",
    "os.chdir(workspace_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce3c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the date range\n",
    "date_range = pd.date_range('1982-01-01', '2018-12-31', freq='M')\n",
    "\n",
    "# The grid size is 360x720 (VPD) and 361x720 (SM)\n",
    "# Initialize arrays with a time dimension (i.e., length of date_range)\n",
    "northern_hemisphere_vpd = np.empty((len(date_range), 180, 720), dtype=np.float32)\n",
    "southern_hemisphere_vpd = np.empty((len(date_range), 180, 720), dtype=np.float32)\n",
    "northern_hemisphere_sm = np.empty((len(date_range), 180, 720), dtype=np.float32)\n",
    "southern_hemisphere_sm = np.empty((len(date_range), 180, 720), dtype=np.float32)\n",
    "\n",
    "# Fill initial arrays with NaN to avoid errors in subsequent calculations\n",
    "northern_hemisphere_vpd.fill(np.nan)\n",
    "southern_hemisphere_vpd.fill(np.nan)\n",
    "northern_hemisphere_sm.fill(np.nan)\n",
    "southern_hemisphere_sm.fill(np.nan)\n",
    "\n",
    "# Define the growing season months for the Northern and Southern Hemispheres\n",
    "northern_months = [4, 5, 6, 7, 8, 9]  \n",
    "southern_months = [10, 11, 12, 1, 2, 3]  \n",
    "\n",
    "# Latitude slices for VPD and SM (note: number of rows differ)\n",
    "vpd_northern_hemisphere_rows = slice(0, 180)  \n",
    "vpd_southern_hemisphere_rows = slice(180, 360)  \n",
    "sm_northern_hemisphere_rows = slice(0, 180)  \n",
    "sm_southern_hemisphere_rows = slice(180, 360) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254806a9",
   "metadata": {},
   "source": [
    "Percentiles and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac1b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_monthly_90th_percentile(vpd_path, start_year, end_year, num_rows, num_cols):\n",
    "    # Initialize arrays\n",
    "    northern_vpd_90th_percentile = np.zeros((12, num_rows, num_cols))\n",
    "    southern_vpd_90th_percentile = np.zeros((12, num_rows, num_cols))\n",
    "    nor_vpd_std = np.zeros((12, num_rows, num_cols))\n",
    "    sou_vpd_std = np.zeros((12, num_rows, num_cols))\n",
    "\n",
    "    # Organize data: create dictionaries to collect all years of data for each month\n",
    "    northern_hemisphere_vpd = {month: [] for month in northern_months}\n",
    "    southern_hemisphere_vpd = {month: [] for month in southern_months}\n",
    "\n",
    "    # Loop through each year and month to collect data\n",
    "    for date in date_range:\n",
    "        month = date.month\n",
    "        year = date.year\n",
    "        # Read VPD data\n",
    "        vpd_file_path = f\"{vpd_path}/VPD_X{year}.{month:02d}.tif\"\n",
    "        if os.path.exists(vpd_file_path):\n",
    "            with rasterio.open(vpd_file_path) as vpd_src:\n",
    "                vpd_data = vpd_src.read(1)  # Read the full global VPD data\n",
    "                # vpd_data[vpd_data < 0] = np.nan  # Replace very small values with NaN to avoid overflow\n",
    "                \n",
    "                # Handle Northern Hemisphere data for April–September\n",
    "                if month in northern_months:\n",
    "                    northern_hemisphere_vpd[month].append(vpd_data[vpd_northern_hemisphere_rows, :])\n",
    "                \n",
    "                # Handle Southern Hemisphere data for October–March\n",
    "                if month in southern_months:\n",
    "                    southern_hemisphere_vpd[month].append(vpd_data[vpd_southern_hemisphere_rows, :])\n",
    "\n",
    "    # Calculate the 90th percentile for each month\n",
    "    for month in range(1, 13):\n",
    "        if month in northern_months:\n",
    "            i = month - 1  # Convert month to array index\n",
    "            if northern_hemisphere_vpd[month]:  # Ensure data exists\n",
    "                data_stack_north = np.stack(northern_hemisphere_vpd[month])\n",
    "                northern_vpd_90th_percentile[i] = np.percentile(data_stack_north, 90, axis=0)\n",
    "                nor_vpd_std[i] = np.nanstd(data_stack_north, axis=0)\n",
    "        if month in southern_months:\n",
    "            i = month - 1\n",
    "            if southern_hemisphere_vpd[month]:\n",
    "                data_stack_south = np.stack(southern_hemisphere_vpd[month])\n",
    "                southern_vpd_90th_percentile[i] = np.percentile(data_stack_south, 90, axis=0)\n",
    "                sou_vpd_std[i] = np.nanstd(data_stack_south, axis=0)\n",
    "    return northern_vpd_90th_percentile, southern_vpd_90th_percentile, nor_vpd_std, sou_vpd_std\n",
    "\n",
    "start_year = 1982\n",
    "end_year = 2018\n",
    "num_rows = 180  \n",
    "num_cols = 720  \n",
    "\n",
    "# Call the function\n",
    "northern_vpd_90th_percentile, southern_vpd_90th_percentile, nor_vpd_std, sou_vpd_std = calculate_monthly_90th_percentile(\n",
    "    vpd_path, start_year, end_year, num_rows, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a2f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_monthly_10th_percentile(sm_path, start_year, end_year, num_rows, num_cols):\n",
    "    # Initialize arrays\n",
    "    northern_sm_10th_percentile = np.zeros((12, num_rows, num_cols))\n",
    "    southern_sm_10th_percentile = np.zeros((12, num_rows, num_cols))\n",
    "    nor_sm_std = np.zeros((12, num_rows, num_cols))\n",
    "    sou_sm_std = np.zeros((12, num_rows, num_cols))\n",
    "\n",
    "    # Organize data: create dictionaries to collect all years of data for each month\n",
    "    northern_hemisphere_sm = {month: [] for month in northern_months}\n",
    "    southern_hemisphere_sm = {month: [] for month in southern_months}\n",
    "\n",
    "    # Loop through each year and month to collect data\n",
    "    for date in date_range:\n",
    "        month = date.month\n",
    "        year = date.year\n",
    "        # Read SM data\n",
    "        sm_file_path = f\"{sm_path}/sm_{year}{month:02d}.tif\"\n",
    "        if os.path.exists(sm_file_path):  \n",
    "            with rasterio.open(sm_file_path) as sm_src:\n",
    "                sm_data = sm_src.read(1)  # Read the full global SM data\n",
    "                \n",
    "                # Process Northern Hemisphere data for April–September\n",
    "                if month in northern_months:\n",
    "                    northern_hemisphere_sm[month].append(sm_data[sm_northern_hemisphere_rows, :])\n",
    "                \n",
    "                # Process Southern Hemisphere data for October–March\n",
    "                if month in southern_months:\n",
    "                    southern_hemisphere_sm[month].append(sm_data[sm_southern_hemisphere_rows, :])\n",
    "\n",
    "    # Calculate the 10th percentile and standard deviation for each month\n",
    "    for month in range(1, 13):\n",
    "        if month in northern_months:\n",
    "            i = month - 1  # Convert month to array index\n",
    "            if northern_hemisphere_sm[month]:  # Ensure data is available\n",
    "                data_stack_north = np.stack(northern_hemisphere_sm[month])\n",
    "                northern_sm_10th_percentile[i] = np.percentile(data_stack_north, 10, axis=0)\n",
    "                nor_sm_std[i] = np.nanstd(data_stack_north, axis=0)\n",
    "        if month in southern_months:\n",
    "            i = month - 1\n",
    "            if southern_hemisphere_sm[month]:\n",
    "                data_stack_south = np.stack(southern_hemisphere_sm[month])\n",
    "                southern_sm_10th_percentile[i] = np.percentile(data_stack_south, 10, axis=0)\n",
    "                sou_sm_std[i] = np.nanstd(data_stack_south, axis=0)\n",
    "    return northern_sm_10th_percentile, southern_sm_10th_percentile, nor_sm_std, sou_sm_std\n",
    "\n",
    "start_year = 1982\n",
    "end_year = 2018\n",
    "num_rows = 180  \n",
    "num_cols = 720  \n",
    "\n",
    "# Call the function\n",
    "northern_sm_10th_percentile, southern_sm_10th_percentile, nor_sm_std, sou_sm_std = calculate_monthly_10th_percentile(\n",
    "    sm_path, start_year, end_year, num_rows, num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize storage arrays with a time dimension (i.e., the length of date_range)\n",
    "NH_vpd = np.empty((len(date_range), 180, 720), dtype=np.float32)\n",
    "SH_vpd = np.empty((len(date_range), 180, 720), dtype=np.float32)\n",
    "NH_sm = np.empty((len(date_range), 180, 720), dtype=np.float32)\n",
    "SH_sm = np.empty((len(date_range), 180, 720), dtype=np.float32)\n",
    "\n",
    "# Read VPD and SM data\n",
    "for idx, date in enumerate(date_range):\n",
    "    month = date.month\n",
    "    year = date.year\n",
    "    # Read VPD data\n",
    "    vpd_file_path = f\"{vpd_path}/VPD_X{year}.{month:02d}.tif\"\n",
    "    if os.path.exists(vpd_file_path):\n",
    "        with rasterio.open(vpd_file_path) as vpd_src:\n",
    "            vpd_data = vpd_src.read(1)  # Read the global VPD data\n",
    "            # vpd_data[vpd_data < 0] = np.nan\n",
    "\n",
    "            # Process Northern Hemisphere data for April–September\n",
    "            if month in northern_months:\n",
    "                NH_vpd[idx, :, :] = vpd_data[vpd_northern_hemisphere_rows, :]\n",
    "\n",
    "            # Process Southern Hemisphere data for October–March\n",
    "            if month in southern_months:\n",
    "                SH_vpd[idx, :, :] = vpd_data[vpd_southern_hemisphere_rows, :]\n",
    "    \n",
    "    # Read SM data\n",
    "    sm_file_path = f\"{sm_path}/sm_{year}{month:02d}.tif\"\n",
    "    if os.path.exists(sm_file_path):\n",
    "        with rasterio.open(sm_file_path) as sm_src:\n",
    "            sm_data = sm_src.read(1)  # Read the global SM data\n",
    "            # sm_data[sm_data < 0] = np.nan\n",
    "\n",
    "            # Process Northern Hemisphere data for April–September\n",
    "            if month in northern_months:\n",
    "                NH_sm[idx, :, :] = sm_data[sm_northern_hemisphere_rows, :]\n",
    "\n",
    "            # Process Southern Hemisphere data for October–March\n",
    "            if month in southern_months:\n",
    "                SH_sm[idx, :, :] = sm_data[sm_southern_hemisphere_rows, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d095298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NH_vpd[NH_vpd < -9999] = np.nan\n",
    "SH_vpd[SH_vpd < -9999] = np.nan\n",
    "NH_sm[NH_sm < -9999] = np.nan\n",
    "SH_sm[SH_sm < -9999] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "065d2342",
   "metadata": {},
   "outputs": [],
   "source": [
    "northern_vpd_90th_percentile[northern_vpd_90th_percentile < -9999] = np.nan\n",
    "southern_vpd_90th_percentile[southern_vpd_90th_percentile < -9999] = np.nan\n",
    "northern_sm_10th_percentile[northern_sm_10th_percentile < -9999] = np.nan\n",
    "southern_sm_10th_percentile[southern_sm_10th_percentile < -9999] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781afe0",
   "metadata": {},
   "source": [
    "Northern Hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d79182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_drought_events(vpd_data, sm_data, vpd_90th, sm_10th):\n",
    "    # Initialize the event array\n",
    "    event = np.empty_like(vpd_data, dtype=bool)\n",
    "    \n",
    "    for month_index in range(vpd_data.shape[0]):\n",
    "        # Map index to month (1–12)\n",
    "        month = month_index % 12 + 1\n",
    "        \n",
    "        if month in [4, 5, 6, 7, 8, 9]:\n",
    "            # Calculate the corresponding index for percentile arrays\n",
    "            percentile_index = month - 1\n",
    "\n",
    "            # Identify drought events: VPD > 90th percentile and SM < 10th percentile\n",
    "            event[month_index] = (vpd_data[month_index] > vpd_90th[percentile_index]) & (sm_data[month_index] < sm_10th[percentile_index])\n",
    "            # event[month_index] = (vpd_data[month_index] > vpd_90th[percentile_index]) \n",
    "            # event[month_index] = sm_data[month_index] < sm_10th[percentile_index]\n",
    "        else:\n",
    "            event[month_index] = np.zeros_like(vpd_data[month_index], dtype=bool)\n",
    "   \n",
    "    event_duration_sum = np.zeros(event.shape[1:], dtype=np.int32)\n",
    "    total_event_count = np.zeros(event.shape[1:], dtype=np.int32)\n",
    "    \n",
    "    # Compute for each grid cell\n",
    "    for i in range(event.shape[1]):  \n",
    "        for j in range(event.shape[2]):  \n",
    "            # Get event time series (Boolean values) for the current grid cell\n",
    "            grid_event = event[:, i, j]\n",
    "            \n",
    "            # Track the number of consecutive drought months\n",
    "            current_duration = 0\n",
    "            for month in range(grid_event.shape[0]):\n",
    "                if grid_event[month]:  # If an event occurs\n",
    "                    current_duration += 1\n",
    "                else:\n",
    "                    # If there was an ongoing event, record its duration and reset\n",
    "                    if current_duration > 0:\n",
    "                        total_event_count[i, j] += 1\n",
    "                        event_duration_sum[i, j] += current_duration\n",
    "                        current_duration = 0\n",
    "\n",
    "            # If the last month still had an ongoing event, record it\n",
    "            if current_duration > 0:\n",
    "                total_event_count[i, j] += 1\n",
    "                event_duration_sum[i, j] += current_duration\n",
    "\n",
    "    # Calculate average duration, avoid division by zero\n",
    "    average_event_duration = np.zeros(event.shape[1:], dtype=np.float32)\n",
    "    frequency = np.zeros(event.shape[1:], dtype=np.float32)\n",
    "    mask = total_event_count > 0\n",
    "    average_event_duration[mask] = event_duration_sum[mask] / total_event_count[mask]\n",
    "    frequency[mask] = total_event_count[mask] / 37  # Normalize by number of years\n",
    "\n",
    "    return event, event_duration_sum, total_event_count, average_event_duration, frequency\n",
    "\n",
    "event00, event_duration_sum00, total_event_count00, average_event_duration00, frequency00 = find_drought_events(\n",
    "    NH_vpd, NH_sm, northern_vpd_90th_percentile, northern_sm_10th_percentile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e6b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate intensity\n",
    "\n",
    "def find_drought_events(vpd_data, sm_data, vpd_90th, sm_10th, vpd_std, sm_std):\n",
    "    # Initialize the event array\n",
    "    event = np.empty_like(vpd_data, dtype=bool)\n",
    "    \n",
    "    # Match monthly data to percentile indices (only April–September are considered, using month cycle)\n",
    "    for month_index in range(vpd_data.shape[0]):\n",
    "        # Map index to month (1–12)\n",
    "        month = month_index % 12 + 1   \n",
    "             \n",
    "        if month in [4, 5, 6, 7, 8, 9]:\n",
    "            # Convert month to percentile index\n",
    "            percentile_index = month - 1\n",
    "\n",
    "            # Drought condition: VPD > 90th percentile and SM < 10th percentile\n",
    "            event[month_index] = (vpd_data[month_index] > vpd_90th[percentile_index]) & (sm_data[month_index] < sm_10th[percentile_index])\n",
    "        else:\n",
    "            event[month_index] = np.zeros_like(vpd_data[month_index], dtype=bool)\n",
    "\n",
    "    event_duration_sum = np.zeros(event.shape[1:], dtype=np.int32)\n",
    "    total_event_count = np.zeros(event.shape[1:], dtype=np.int32)\n",
    "    total_intensity = np.zeros(event.shape[1:], dtype=np.float32)\n",
    "\n",
    "    # Compute for each grid cell\n",
    "    for i in range(event.shape[1]):  \n",
    "        for j in range(event.shape[2]): \n",
    "            grid_event = event[:, i, j]\n",
    "            \n",
    "            # Track number of consecutive drought months\n",
    "            current_duration = 0\n",
    "            event_sm_sum = 0\n",
    "            event_vpd_sum = 0\n",
    "\n",
    "            for month in range(grid_event.shape[0]):\n",
    "                month_in_year = month % 12  \n",
    "                if grid_event[month]:  \n",
    "                    current_duration += 1\n",
    "                    event_sm_sum += ((sm_data[month, i, j] - sm_10th[month_in_year, i, j]) / sm_std[month_in_year, i, j]) ** 2\n",
    "                    event_vpd_sum += ((vpd_data[month, i, j] - vpd_90th[month_in_year, i, j]) / vpd_std[month_in_year, i, j]) ** 2\n",
    "                else:\n",
    "                    # If a drought event was ongoing, record its duration and intensity, then reset\n",
    "                    if current_duration > 0:\n",
    "                        total_event_count[i, j] += 1\n",
    "                        event_duration_sum[i, j] += current_duration\n",
    "                        \n",
    "                        intensity_val = np.sqrt((event_sm_sum + event_vpd_sum) / (2 * current_duration))\n",
    "                        total_intensity[i, j] += intensity_val\n",
    "\n",
    "                        # Reset cumulative values\n",
    "                        current_duration = 0\n",
    "                        event_sm_sum = 0\n",
    "                        event_vpd_sum = 0   \n",
    "\n",
    "            # If the event continues through the last month, record it\n",
    "            if current_duration > 0:\n",
    "                total_event_count[i, j] += 1\n",
    "                event_duration_sum[i, j] += current_duration\n",
    "                intensity_val = np.sqrt((event_sm_sum + event_vpd_sum) / (2 * current_duration))\n",
    "                total_intensity[i, j] += intensity_val\n",
    "\n",
    "    # Calculate average intensity, avoid division by zero\n",
    "    average_event_intensity = np.zeros(event.shape[1:], dtype=np.float32)\n",
    "    mask = total_event_count > 0\n",
    "    average_event_intensity[mask] = total_intensity[mask] / total_event_count[mask]\n",
    "\n",
    "    return average_event_intensity, total_intensity\n",
    "\n",
    "average_event_intensity00, total_intensity00 = find_drought_events(\n",
    "    NH_vpd, NH_sm, northern_vpd_90th_percentile, northern_sm_10th_percentile, nor_vpd_std, nor_sm_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4754db2f",
   "metadata": {},
   "source": [
    "Southern Hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9528dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_drought_events(vpd_data, sm_data, vpd_90th, sm_10th):\n",
    "    # Initialize the event array\n",
    "    event = np.empty_like(vpd_data, dtype=bool)\n",
    "    \n",
    "    for month_index in range(vpd_data.shape[0]):\n",
    "        # Map index to month (1–12)\n",
    "        month = month_index % 12 + 1\n",
    "        # print(f\"Month index: {month_index}, Corresponding percentile index: {month}\")\n",
    "        \n",
    "        if month in [1, 2, 3, 10, 11, 12]:\n",
    "            # Calculate the corresponding index for percentile arrays\n",
    "            percentile_index = month - 1\n",
    "\n",
    "            # Identify drought events: VPD > 90th percentile and SM < 10th percentile\n",
    "            event[month_index] = (vpd_data[month_index] > vpd_90th[percentile_index]) & (sm_data[month_index] < sm_10th[percentile_index])\n",
    "            # event[month_index] = (vpd_data[month_index] > vpd_90th[percentile_index]) \n",
    "            # event[month_index] = sm_data[month_index] < sm_10th[percentile_index]\n",
    "        else:\n",
    "            # For other months, set all values to False (keep default 0 state)\n",
    "            event[month_index] = np.zeros_like(vpd_data[month_index], dtype=bool)\n",
    "   \n",
    "    event_duration_sum = np.zeros(event.shape[1:], dtype=np.int32)\n",
    "    total_event_count = np.zeros(event.shape[1:], dtype=np.int32)\n",
    "    \n",
    "    # Compute for each grid cell\n",
    "    for i in range(event.shape[1]):  \n",
    "        for j in range(event.shape[2]):  \n",
    "            # Get event time series (Boolean values) for the current grid cell\n",
    "            grid_event = event[:, i, j]\n",
    "            \n",
    "            # Track the number of consecutive drought months\n",
    "            current_duration = 0\n",
    "            for month in range(grid_event.shape[0]):\n",
    "                if grid_event[month]:  # If an event occurs\n",
    "                    current_duration += 1\n",
    "                else:\n",
    "                    # If there was an ongoing event, record its duration and reset\n",
    "                    if current_duration > 0:\n",
    "                        total_event_count[i, j] += 1\n",
    "                        event_duration_sum[i, j] += current_duration\n",
    "                        current_duration = 0\n",
    "\n",
    "            # If the last month still had an ongoing event, record it\n",
    "            if current_duration > 0:\n",
    "                total_event_count[i, j] += 1\n",
    "                event_duration_sum[i, j] += current_duration\n",
    "\n",
    "    # Calculate average duration, avoid division by zero\n",
    "    average_event_duration = np.zeros(event.shape[1:], dtype=np.float32)\n",
    "    frequency = np.zeros(event.shape[1:], dtype=np.float32)\n",
    "    mask = total_event_count > 0\n",
    "    average_event_duration[mask] = event_duration_sum[mask] / total_event_count[mask]\n",
    "    frequency[mask] = total_event_count[mask] / 37  # Normalize by number of years\n",
    "\n",
    "    return event, event_duration_sum, total_event_count, average_event_duration, frequency\n",
    "\n",
    "event01, event_duration_sum01, total_event_count01, average_event_duration01, frequency01 = find_drought_events(SH_vpd, SH_sm, southern_vpd_90th_percentile, southern_sm_10th_percentile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b241f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate intensity\n",
    "\n",
    "def find_drought_events(vpd_data, sm_data, vpd_90th, sm_10th, vpd_std, sm_std):\n",
    "    # Initialize the event array\n",
    "    event = np.empty_like(vpd_data, dtype=bool)\n",
    "    \n",
    "    # Match monthly data to percentile indices (only April–September are considered, using month cycle)\n",
    "    for month_index in range(vpd_data.shape[0]):\n",
    "        # Map index to month (1–12)\n",
    "        month = month_index % 12 + 1   \n",
    "             \n",
    "        if month in [1, 2, 3, 10, 11, 12]:\n",
    "            # Convert month to percentile index\n",
    "            percentile_index = month - 1\n",
    "\n",
    "            # Drought condition: VPD > 90th percentile and SM < 10th percentile\n",
    "            event[month_index] = (vpd_data[month_index] > vpd_90th[percentile_index]) & (sm_data[month_index] < sm_10th[percentile_index])\n",
    "        else:\n",
    "            event[month_index] = np.zeros_like(vpd_data[month_index], dtype=bool)\n",
    "\n",
    "    event_duration_sum = np.zeros(event.shape[1:], dtype=np.int32)\n",
    "    total_event_count = np.zeros(event.shape[1:], dtype=np.int32)\n",
    "    total_intensity = np.zeros(event.shape[1:], dtype=np.float32)\n",
    "\n",
    "    # Compute for each grid cell\n",
    "    for i in range(event.shape[1]):  \n",
    "        for j in range(event.shape[2]): \n",
    "            grid_event = event[:, i, j]\n",
    "            \n",
    "            # Track number of consecutive drought months\n",
    "            current_duration = 0\n",
    "            event_sm_sum = 0\n",
    "            event_vpd_sum = 0\n",
    "\n",
    "            for month in range(grid_event.shape[0]):\n",
    "                month_in_year = month % 12  \n",
    "                if grid_event[month]:  \n",
    "                    current_duration += 1\n",
    "                    event_sm_sum += ((sm_data[month, i, j] - sm_10th[month_in_year, i, j]) / sm_std[month_in_year, i, j]) ** 2\n",
    "                    event_vpd_sum += ((vpd_data[month, i, j] - vpd_90th[month_in_year, i, j]) / vpd_std[month_in_year, i, j]) ** 2\n",
    "                else:\n",
    "                    # If a drought event was ongoing, record its duration and intensity, then reset\n",
    "                    if current_duration > 0:\n",
    "                        total_event_count[i, j] += 1\n",
    "                        event_duration_sum[i, j] += current_duration\n",
    "                        \n",
    "                        intensity_val = np.sqrt((event_sm_sum + event_vpd_sum) / (2 * current_duration))\n",
    "                        total_intensity[i, j] += intensity_val\n",
    "\n",
    "                        # Reset cumulative values\n",
    "                        current_duration = 0\n",
    "                        event_sm_sum = 0\n",
    "                        event_vpd_sum = 0   \n",
    "\n",
    "            # If the event continues through the last month, record it\n",
    "            if current_duration > 0:\n",
    "                total_event_count[i, j] += 1\n",
    "                event_duration_sum[i, j] += current_duration\n",
    "                intensity_val = np.sqrt((event_sm_sum + event_vpd_sum) / (2 * current_duration))\n",
    "                total_intensity[i, j] += intensity_val\n",
    "\n",
    "    # Calculate average intensity, avoid division by zero\n",
    "    average_event_intensity = np.zeros(event.shape[1:], dtype=np.float32)\n",
    "    mask = total_event_count > 0\n",
    "    average_event_intensity[mask] = total_intensity[mask] / total_event_count[mask]\n",
    "\n",
    "    return average_event_intensity, total_intensity\n",
    "\n",
    "average_event_intensity01, total_intensity01 = find_drought_events(SH_vpd, SH_sm, southern_vpd_90th_percentile, southern_sm_10th_percentile, sou_vpd_std, sou_sm_std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f9ad79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebe702c4",
   "metadata": {},
   "source": [
    "save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec82e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output resluts\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# Loop through each year and month to collect data\n",
    "for date in date_range:\n",
    "    month = date.month\n",
    "    year = date.year\n",
    "    vpd_file_path = f\"{vpd_path}/VPD_X{year}.{month:02d}.tif.tif\"\n",
    "    if os.path.exists(vpd_file_path):\n",
    "        with rasterio.open(vpd_file_path) as vpd_src:\n",
    "            vpd_data = vpd_src.read(1)  \n",
    "\n",
    "# Use the spatial reference and transform from the original data\n",
    "transform = vpd_src.transform\n",
    "crs = vpd_src.crs\n",
    "\n",
    "# Output file path\n",
    "output_path = r\"G:\\paper01\\TEST\\frequency00.tif\"\n",
    "\n",
    "# Create the output raster file\n",
    "with rasterio.open(\n",
    "    output_path, 'w',\n",
    "    driver='GTiff',         \n",
    "    height=frequency00.shape[0],  \n",
    "    width=frequency00.shape[1],   \n",
    "    count=1,               \n",
    "    dtype=rasterio.float32,  \n",
    "    crs=crs,              \n",
    "    transform=transform,   \n",
    "    nodata=np.nan        \n",
    ") as dst:\n",
    "    dst.write(frequency00.astype(np.float32), 1)  \n",
    "\n",
    "print(\"Data successfully written to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b947e2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
